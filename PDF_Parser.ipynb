{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ocr_release.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj_I1mSeJM-h"
      },
      "source": [
        "# PDF->Page->Text\r\n",
        "\r\n",
        "This notebook processes PDFs to TXT by splitting the page and performing OCR for each page of the PDF.\r\n",
        "\r\n",
        "## Outline of the Workflow\r\n",
        "* Mount the notebook to the Google Colab\r\n",
        "* Import Libraries and packages\r\n",
        "* Format params, search, and get files from Google Drive\r\n",
        "* Convert pdf pages to jpeg files\r\n",
        "* Convert jpeg files to txt (string); save them in output_file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zMyFKpl6aRm"
      },
      "source": [
        "### Modify this cell only\n",
        "top = '1GalyWQAGD03OivOT6gMpRskYxEbXpkQi' \n",
        "input_dir = '/content/drive/My Drive/AWCA/Colab_notebooks/OCR/OCR_PDF2Page/k9_input/'  ##must start and end with a \"/\"\n",
        "output_dir = '/content/drive/My Drive/AWCA/Colab_notebooks/OCR/OCR_PDF2Page/k9_input_results/' ##must start and end with a \"/\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsPmFf_L5DgG"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "service = build('drive', 'v3')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW8wp52u545x",
        "outputId": "1049e7a1-b2b8-4235-93d1-6ead2eed4c7c"
      },
      "source": [
        "# Run this to mount the Notebook in your Google Drive account \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW00ocJwgzin"
      },
      "source": [
        "One-time installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OJnTKpEIRcZ",
        "outputId": "5aa5a4f8-b289-420e-df86-7eb9c1de9d3d"
      },
      "source": [
        "!pip3 install pdf2image\n",
        "!apt-get install poppler-utils \n",
        "!pip3 install pytesseract\n",
        "!pip3 install pdf2image\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install PyPDF2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from pdf2image) (7.0.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (0.62.0-2ubuntu2.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from pdf2image) (7.0.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.6/dist-packages (1.26.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SURjdsmHg4sU"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkN4WeGT5_Lv"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import sys\n",
        "from apiclient.discovery import build  # pip install google-api-python-client\n",
        "from pdf2image import convert_from_path # the module can convert PDF to a PIL Image object\n",
        "from PIL import Image\n",
        "import pytesseract #OCR tool; recognizes the text embedded in images\n",
        "import sys \n",
        "from PyPDF2 import PdfFileReader, PdfFileWriter #the classes can read PDFs, split PDFs, and extract data\n",
        "from collections import Counter # track the number of occurence of a value\n",
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkTXA5nsg7_8"
      },
      "source": [
        "Logging setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgMU_Rqr6B7P"
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(threadName)-10s %(message)s',)\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTmMACd46sgF"
      },
      "source": [
        "### Formatting and searching the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AneoqAF8TON"
      },
      "source": [
        "def iterfiles(name=None, is_folder=None, parent=None, order_by='folder,name,createdTime'):  \n",
        "    q = []\n",
        "    if name is not None:\n",
        "        q.append(\"name = '%s'\" % name.replace(\"'\", \"\\\\'\"))\n",
        "    if is_folder is not None:\n",
        "        q.append(\"mimeType %s '%s'\" % ('=' if is_folder else '!=', FOLDER))\n",
        "    if parent is not None:\n",
        "        q.append(\"'%s' in parents\" % parent.replace(\"'\", \"\\\\'\"))\n",
        "    fields = ['id', 'title', 'mimeType']\n",
        "    params = {'pageToken': None, 'orderBy': order_by,\n",
        "              'fields': 'kind, nextPageToken, incompleteSearch, files(id, name, mimeType, md5Checksum, webViewLink, createdTime, modifiedTime, size)'}\n",
        "    if q:\n",
        "        params['q'] = ' and '.join(q)\n",
        "    while True:\n",
        "        logger.debug('params {}'.format(params))\n",
        "        response = service.files().list(**params).execute() # searches the files which match **params\n",
        "        logger.debug('response {}'.format(response))        \n",
        "        for f in response['files']:\n",
        "            yield f\n",
        "        try:\n",
        "            params['pageToken'] = response['nextPageToken'] # changes the page token of the file to next page token\n",
        "        except KeyError:\n",
        "            return"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWsZIpTMe-_C"
      },
      "source": [
        "### Search all the sub-directories and files inside the initial directory\r\n",
        "\r\n",
        "Uses `iterfiles()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I27duQMa9MyT"
      },
      "source": [
        "def walk(top='root', by_name=False, snapshot_file='stack_snapshot.json'):\n",
        "    print(\"walk function is called\")\n",
        "  # Search all the sub-directories and files inside the initial directory\n",
        "    try:\n",
        "        with open(snapshot_file) as f:\n",
        "            stack = json.loads(f.read()) #accepts a string, read the json file\n",
        "    except FileNotFoundError:\n",
        "        logger.info('no stack snapshot found')\n",
        "        stack = None\n",
        "    if not stack:\n",
        "      # if reading the json file was unsuccessful, check the reasons\n",
        "        if by_name:\n",
        "            top, = iterfiles(name=top, is_folder=True) # top as name\n",
        "        else:\n",
        "            top = service.files().get(fileId=top).execute() #top as fileId\n",
        "            if top['mimeType'] != FOLDER:\n",
        "                raise ValueError('not a folder: %r' % top)\n",
        "        stack = [([top['name']], top)]\n",
        "    while stack:\n",
        "      # if stack is not empty, noting down its information\n",
        "        logger.info('stack size {}'.format(len(stack)))\n",
        "        with open(snapshot_file, 'w') as file:\n",
        "            file.write(json.dumps(stack))\n",
        "        path, top = stack.pop()\n",
        "        logger.info('dir {}'.format(path))\n",
        "        dirs, files = is_file = [], []\n",
        "        for f in iterfiles(parent=top['id']):\n",
        "            is_file[f['mimeType'] != FOLDER].append(f)\n",
        "        logger.info('subdirs {} files {}'.format(len(dirs), len(files)))\n",
        "        yield path, top, dirs, files\n",
        "        if dirs:\n",
        "            logger.debug('dirs {}'.format(dirs))\n",
        "            logger.debug('path {}'.format(path))            \n",
        "            newstuff = [(path + [d['name']], d) for d in reversed(dirs)]\n",
        "            logger.debug('extend: {}'.format(newstuff))\n",
        "            stack.extend(newstuff)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1ArdxZJeQlY"
      },
      "source": [
        "### Gives information about a file, including its ID, md5, size, create/modify time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsSjqmmx-nr-"
      },
      "source": [
        "def extract_metadata(node):\n",
        "    md5Checksum = node.get('md5Checksum', 'None')\n",
        "    size = node.get('size', 'None')\n",
        "    mimeType = node.get('mimeType', 'None')\n",
        "    webViewLink = node.get('webViewLink', 'None')\n",
        "    id = node.get('id', 'None')\n",
        "    createdTime = node.get('createdTime', 'None')\n",
        "    modifiedTime = node.get('modifiedTime', 'None')\n",
        "    name = node.get('name', 'None')\n",
        "    return id, md5Checksum, size, mimeType, createdTime, modifiedTime"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-LDCx-sfCxp"
      },
      "source": [
        "### OCR on a Directory\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "#### *Main Idea*: \r\n",
        "Takes in a directory, creates a folder of pages for each PDF/document, and uses OCR to convert all pages to computer text (txt).\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "#### *Imports*: \r\n",
        "* PdfFileReader / PdfFileWriter: Useful for reading and saving PDFs.\r\n",
        "* Counter: Counts the number of each element and stores the each unique as a key with the frequency as dictionary values. Subclass of dict. Used to count frequency of words in a PDF.\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "#### *Outer loop*: Reads in all pdfs from the input directory from `walk()`. Splits a pdf into individual pages which will each be run into the inner for loop. Gets specific information about a file using `extract_metadata` and saves that in a CSV. Creates folder for output if one does not already exist.\r\n",
        "* convert_from_path: takes in a PDF and outputs an image for each page in the PDF\r\n",
        "* img_count: index for inner for loop. Tracks page number for a pdf.\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "#### *Inner `page` loop*: For each page, sets Flag to False. Runs OCR with `pytesseract.[FILENAME]` on the default orientation and all 90-degree rotations: 0째, 90째, 180째, 270째. If any orientation can be read, Flag is set to True and the text of the page is written to output. If none of the rotations generates a proper output, the page is not used.\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVdTctWY-r4w"
      },
      "source": [
        "def big_loop(top, csvwriter, maxfiles):   \n",
        "  fc = 0\n",
        "  if os.path.isdir(output_dir) == False:\n",
        "    os.mkdir(output_dir)\n",
        "  for path, root, dirs, files in walk(top=top, by_name=False, snapshot_file=snapshot_file):\n",
        "      # note 'by_name' is currently not used\n",
        "      dirpath = '/'.join(path)\n",
        "      id, _, _, mimeType, createdTime, modifiedTime = extract_metadata(root)\n",
        "      # for directories we use the md5Checksum field to hold the dir count\n",
        "      md5Checksum = len(dirs) \n",
        "      # for directories we use the size field to hold the plain file count\n",
        "      size = len(files)\n",
        "      row = [id, md5Checksum, size, mimeType, createdTime, modifiedTime, dirpath]\n",
        "      csvwriter.writerow(row)\n",
        "      # we count each dir as a file for the purpose of maxfiles\n",
        "      fc = fc + 1\n",
        "      for pdf_index in range(len(files)):\n",
        "        #Here we conduct page split and put it in a folder\n",
        "        folder_name = str(id)+'/' ## This is how google id of the pdf gets to be the folder's name of that pdf\n",
        "        folder_name_failed = str(id)+'/failed_pages.txt'  ## failed paged are specified in terms of filename and pages\n",
        "        pdf_numbers = len(files)\n",
        "        pages = convert_from_path(input_dir[:-1]+'/'+files[pdf_index]['name'])\n",
        "        if os.path.isdir(output_dir+folder_name) == False:\n",
        "          print(\"New folder is created\")\n",
        "          os.mkdir(output_dir+folder_name)\n",
        "        csv_id = []\n",
        "        csv_text = []\n",
        "        output_error_file = output_dir +folder_name+ 'failed_pages.txt' #Page the are failed in ocr process specified to pdf name and page number\n",
        "        for page_idx, page in enumerate(pages):\n",
        "          img_count = page_idx + 1\n",
        "          print(\"image idx: \", img_count)\n",
        "          save_name = output_dir+folder_name+\"page_\"+str(img_count)+\".jpg\"\n",
        "          page.save(save_name, 'JPEG')\n",
        "          ##Save the images and csv. \n",
        "          flag = True ##Currently disabling the oritation checker. Replace with a better scheme\n",
        "          # for i in range(4):\n",
        "          #   text = str(((pytesseract.image_to_string(Image.open(save_name)))))\n",
        "          #   cnt = Counter()\n",
        "          #   cnt.update(text.split())\n",
        "          #   # print(cnt['the'],cnt['de'],cnt['bu'],cnt['im'],cnt['che'],cnt['del'],cnt['e'],cnt['la'])\n",
        "          #   if ((cnt['the'] < 3) == True and (cnt['de'] < 3) == True and (cnt['bu'] < 3) == True and (cnt['im'] < 3) == True and ((cnt['e'] + cnt['che'] + cnt['del'] + cnt['la'] < 5) == True)):\n",
        "          #     page2 = page.rotate(90*i)\n",
        "          #     page2.save(save_name, 'JPEG')\n",
        "          #   else:\n",
        "          #     flag = True\n",
        "          #     break\n",
        "          if flag == False:\n",
        "            f_error = open(output_error_file, \"a\")\n",
        "            message = \"Page \" + str(img_count) + \" failed to find the correct orientation.\\n\"\n",
        "            f_error.write(message)\n",
        "            f_error.close() \n",
        "          else:\n",
        "            # converts images to strings\n",
        "            text = str(((pytesseract.image_to_string(Image.open(save_name)))))\n",
        "            csv_text.append(text)\n",
        "            csv_id.append(img_count)\n",
        "      \n",
        "        df = pd.DataFrame({'page id':csv_id, 'page text':csv_text})\n",
        "        print(\"csv saved at \" + output_dir+folder_name+\"page.csv\")\n",
        "        df.to_csv(output_dir+folder_name+\"page.csv\")\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hofddHznIMfn"
      },
      "source": [
        "### Sets up output CSV file and calls `big_loop()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ_NU2-8-uqm"
      },
      "source": [
        "def catalog_walk(top):    ## pass in folder link\n",
        "  snapshot_file = '/snapshot2021'\n",
        "  csvoptions = {'dialect': csv.excel}\n",
        " \n",
        "  OUTFILE = open(\"/content/drive/My Drive/catalog_not_in_use.csv\", \"a\")\n",
        "  csvwriter = csv.writer(OUTFILE)\n",
        "  maxfiles = 100\n",
        "  big_loop(top, csvwriter, maxfiles)\n",
        "  OUTFILE.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRQ9MZBW6jLz"
      },
      "source": [
        "### Specifies input and output directories and calls `catalog_walk()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcsIxyOBBRhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9393838f-aac3-4214-cbbe-5993da5dcb25"
      },
      "source": [
        "snapshot_file = '/snapshot2021.txt'\n",
        "FOLDER = 'application/vnd.google-apps.folder'\n",
        "catalog_walk(top)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-19 06:48:38,384 INFO MainThread stack size 1\n",
            "2021-02-19 06:48:38,386 INFO MainThread dir ['k9_input']\n",
            "2021-02-19 06:48:38,393 INFO MainThread URL being requested: GET https://www.googleapis.com/drive/v3/files?orderBy=folder%2Cname%2CcreatedTime&fields=kind%2C+nextPageToken%2C+incompleteSearch%2C+files%28id%2C+name%2C+mimeType%2C+md5Checksum%2C+webViewLink%2C+createdTime%2C+modifiedTime%2C+size%29&q=%271GalyWQAGD03OivOT6gMpRskYxEbXpkQi%27+in+parents&alt=json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "walk function is called\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-19 06:48:38,828 INFO MainThread subdirs 0 files 2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New folder is created\n",
            "image idx:  1\n",
            "image idx:  2\n",
            "image idx:  3\n",
            "/content/drive/My Drive/AWCA/Colab_notebooks/OCR/OCR_PDF2Page/k9_input_results/1GalyWQAGD03OivOT6gMpRskYxEbXpkQi/page.csv\n",
            "image idx:  1\n",
            "image idx:  2\n",
            "image idx:  3\n",
            "/content/drive/My Drive/AWCA/Colab_notebooks/OCR/OCR_PDF2Page/k9_input_results/1GalyWQAGD03OivOT6gMpRskYxEbXpkQi/page.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}